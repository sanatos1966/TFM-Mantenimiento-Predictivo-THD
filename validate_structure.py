
import os
import sys
import json
from pathlib import Path
import pandas as pd

def validate_project_structure():
    """
    Validate the complete TFM project structure and files
    """
    print("=== VALIDACI√ìN ESTRUCTURA PROYECTO TFM ===\n")

    # Expected project structure
    expected_structure = {
        'files': [
            'TFM_Pipeline_Real_Final_20250826_1951.py',
            'README.md',
            'LICENSE',
            '.gitignore'
        ],
        'directories': {
            'src': ['__init__.py'],
            'src/utils': ['__init__.py'],
            'config': ['config.json'],
            'data': ['datos_completos_tfm.csv', 'datos_completos_tfm.xlsx'],
            'tests': ['__init__.py'],
            'docs': [],
            'output': []
        }
    }

    # Check root files
    print("üìÅ Archivos ra√≠z:")
    for file in expected_structure['files']:
        exists = os.path.exists(file)
        status = "‚úÖ" if exists else "‚ùå"
        print(f"  {status} {file}")

    # Check directories and their contents
    print("\nüìÇ Directorios y contenido:")
    for dir_path, files in expected_structure['directories'].items():
        dir_exists = os.path.exists(dir_path)
        status = "‚úÖ" if dir_exists else "‚ùå"
        print(f"  {status} {dir_path}/")

        if dir_exists and files:
            for file in files:
                file_path = os.path.join(dir_path, file)
                file_exists = os.path.exists(file_path)
                file_status = "‚úÖ" if file_exists else "‚ùå"
                print(f"    {file_status} {file}")

    # Validate configuration file
    print("\nüîß Validaci√≥n configuraci√≥n:")
    config_path = 'config/config.json'
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)

            # Check ML parameters
            if 'ml_parameters' in config:
                print("  ‚úÖ Par√°metros ML encontrados")

                # Check Isolation Forest parameters
                if 'isolation_forest' in config['ml_parameters']:
                    if_params = config['ml_parameters']['isolation_forest']
                    expected_contamination = 0.004319
                    actual_contamination = if_params.get('contamination', 0)

                    if abs(actual_contamination - expected_contamination) < 0.000001:
                        print(f"  ‚úÖ Contamination correcto: {actual_contamination}")
                    else:
                        print(f"  ‚ùå Contamination incorrecto: {actual_contamination} (esperado: {expected_contamination})")

                    expected_estimators = 200
                    actual_estimators = if_params.get('n_estimators', 0)

                    if actual_estimators == expected_estimators:
                        print(f"  ‚úÖ N_estimators correcto: {actual_estimators}")
                    else:
                        print(f"  ‚ùå N_estimators incorrecto: {actual_estimators} (esperado: {expected_estimators})")

                # Check DBSCAN parameters
                if 'dbscan' in config['ml_parameters']:
                    dbscan_params = config['ml_parameters']['dbscan']
                    expected_eps = 1.2
                    actual_eps = dbscan_params.get('eps', 0)

                    if abs(actual_eps - expected_eps) < 0.1:
                        print(f"  ‚úÖ EPS correcto: {actual_eps}")
                    else:
                        print(f"  ‚ùå EPS incorrecto: {actual_eps} (esperado: {expected_eps})")
            else:
                print("  ‚ùå No se encontraron par√°metros ML")

        except Exception as e:
            print(f"  ‚ùå Error leyendo configuraci√≥n: {e}")
    else:
        print("  ‚ùå Archivo config.json no encontrado")

    # Validate data files
    print("\nüìä Validaci√≥n archivos de datos:")
    data_files = ['data/datos_completos_tfm.csv', 'data/datos_completos_tfm.xlsx']

    for data_file in data_files:
        if os.path.exists(data_file):
            try:
                if data_file.endswith('.csv'):
                    df = pd.read_csv(data_file)
                else:
                    df = pd.read_excel(data_file)

                print(f"  ‚úÖ {data_file}: {len(df)} registros, {len(df.columns)} columnas")

                # Check for expected columns
                expected_cols = ['timestamp', 'compressor', 'vibration', 'current', 'thd']
                missing_cols = [col for col in expected_cols if col not in df.columns]
                if missing_cols:
                    print(f"    ‚ö†Ô∏è  Columnas faltantes: {missing_cols}")
                else:
                    print("    ‚úÖ Todas las columnas esperadas presentes")

            except Exception as e:
                print(f"  ‚ùå Error leyendo {data_file}: {e}")
        else:
            print(f"  ‚ùå {data_file} no encontrado")

    # Check Python modules can be imported
    print("\nüêç Validaci√≥n m√≥dulos Python:")
    try:
        sys.path.insert(0, '.')
        import src
        print("  ‚úÖ M√≥dulo 'src' importado correctamente")
    except Exception as e:
        print(f"  ‚ùå Error importando 'src': {e}")

    try:
        import src.utils
        print("  ‚úÖ M√≥dulo 'src.utils' importado correctamente")
    except Exception as e:
        print(f"  ‚ùå Error importando 'src.utils': {e}")

    print("\n=== VALIDACI√ìN COMPLETA ===")

if __name__ == "__main__":
    validate_project_structure()
